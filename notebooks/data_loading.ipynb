{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b9002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d321ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PrinciaFernandes\\\\Mresult\\\\Phenomix\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2857be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3c9c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PrinciaFernandes\\\\Mresult\\\\Phenomix'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4cfda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from src.database.load_vector_data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f6eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data\n",
      "Data Extraction Completed\n",
      "Chunking Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Batches: 100%|██████████| 5/5 [01:53<00:00, 22.63s/it]\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader()\n",
    "records = dataloader.get_records()\n",
    "document = dataloader.data_chuncking(records)\n",
    "vector_db = dataloader.get_vector_db()\n",
    "\n",
    "# Process documents in batches\n",
    "BATCH_SIZE = 500\n",
    "for i in tqdm(range(0, len(document), BATCH_SIZE), desc=\"Embedding Batches\"):\n",
    "    batch = document[i:i + BATCH_SIZE]  # Get batch slice\n",
    "    vector_db.add_documents(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2f34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f64799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "from src.prompts.Prompts import Filter_template ,Generator_template\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "from src.config import VECTORDB_DIR\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import Faithfulness,LLMContextRecall,FactualCorrectness,LLMContextPrecisionWithReference,NoiseSensitivity\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from google import generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbd11535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyDkX0O1Sqd9L1FKvctL-qBFoCNU8hnoNGI'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a5436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "# api_key = os.getenv(\"API_KEY\")\n",
    "api_key = \"AIzaSyDkX0O1Sqd9L1FKvctL-qBFoCNU8hnoNGI\"\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "\n",
    "        \n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key)\n",
    "        self.vector_db = Chroma(embedding_function=self.embeddings, persist_directory=r'data\\Chatbot_vector_db')\n",
    "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=api_key)\n",
    "        self.parser = JsonOutputParser()\n",
    "        self.filtering_chain = Filter_template | self.llm | self.parser\n",
    "        self.generator_chain = Generator_template | self.llm\n",
    "        self.evaluator_llm = LangchainLLMWrapper(self.llm)\n",
    "    \n",
    "    def get_result(self, query):\n",
    "\n",
    "        self.query = query\n",
    "        lower_query = query.lower()\n",
    "        filtering_result = self.filtering_chain.invoke({\"query\" : lower_query})\n",
    "        \n",
    "        if filtering_result:\n",
    "            metadata_filter = filtering_result\n",
    "        else:\n",
    "            metadata_filter = None\n",
    "        retriever = self.vector_db.as_retriever(search_type=\"mmr\", search_kwargs = {\"k\": 4, \"filter\":metadata_filter, 'fetch_k':1000})\n",
    "        response = retriever.invoke(query)\n",
    "\n",
    "        retrieved_contexts = [f\"content:{doc.page_content}, metadata: {doc.metadata} \" for doc in response]\n",
    "        \n",
    "        reference = ', '.join([doc.page_content for doc in response])\n",
    "\n",
    "        tupled_doc = [(doc.metadata,doc.page_content) for doc in response]\n",
    "\n",
    "        result = self.generator_chain.invoke({\"query\": query, \"content\" : tupled_doc})\n",
    "\n",
    "        self.ragas(query, result.content, retrieved_contexts,reference)\n",
    "        return result.content\n",
    "    \n",
    "\n",
    "    def ragas(self,query,generated_response,retrieved_documents,reference):\n",
    "\n",
    "        self.data = {\n",
    "            \"user_input\":[query],\n",
    "            \"response\":[generated_response],\n",
    "            \"retrieved_contexts\":[retrieved_documents],\n",
    "            \"reference\":[reference]\n",
    "        }\n",
    "\n",
    "        self.dataset = Dataset.from_dict(self.data)\n",
    "\n",
    "        self.metrics = [\n",
    "            Faithfulness(),\n",
    "            LLMContextRecall(),\n",
    "            LLMContextPrecisionWithReference(),\n",
    "            NoiseSensitivity()\n",
    "        ]\n",
    "\n",
    "        result = evaluate(dataset=self.dataset,metrics=self.metrics,llm=self.evaluator_llm)\n",
    "        \n",
    "        print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c37b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chatbot = ChatBot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5755284",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is data sources and coding system of BMI?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea76555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9908dc53f254a4c8fc743eaf9f78d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 1.0000, 'context_recall': 1.0000, 'llm_context_precision_with_reference': 1.0000, 'noise_sensitivity(mode=relevant)': 0.0000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'According to the content, the data source for BMI is QResearch, and the coding system is Read codes v2.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.get_result(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cedeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499eef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
